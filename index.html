<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8" />
    <title>Yueying Tian</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            color: #333;
            background-color: #f8f9fa;
        }
        
        /* 页眉样式 */
        header {
            background-color: #e0dccd;
            color: rgb(120, 120, 120);
            text-align: center;
            padding: 1rem 0;
            box-shadow: 0 2px 5px rgba(0,0,0,0.1);
        }
        
        header h1 {
            font-size: 2rem;
            margin-bottom: 0.5rem;
        }
        
        .header-subtitle {
            font-size: 1rem;
            opacity: 0.9;
        }
        
        /* 主要内容区域 */
        .container {
            max-width: 800px;
            margin: 2rem auto;
            padding: 0 20px;
            background-color: white;
            border-radius: 10px;
            box-shadow: 0 4px 6px rgba(0,0,0,0.1);
            min-height: calc(100vh - 200px);
        }
        
        .content {
            padding: 2rem;
            text-align: center;
        }
        
        /* 个人信息区域 */
        .profile-section {
            margin-bottom: 2rem;
            padding-bottom: 2rem;
            border-bottom: 2px solid #eee;
        }
        
        .profile-img {
            border-radius: 50%;
            margin-bottom: 1rem;
            box-shadow: 0 4px 8px rgba(0,0,0,0.1);
        }
        
        .contact-info {
            margin: 1rem 0;
        }
        
        .contact-info p {
            margin: 0.5rem 0;
            font-size: 1rem;
        }
        
        /* 章节标题 - 修改为左对齐并去掉下划线 */
        h1 {
            color: #303030;
            margin: 2rem 0 1rem 0;
            font-size: 1.5rem;
            text-align: left;
            max-width: 700px;
            margin-left: auto;
            margin-right: auto;
        }
        
        /* 段落样式 */
        p {
            margin-bottom: 1rem;
            text-align: left;
            max-width: 700px;
            margin-left: auto;
            margin-right: auto;
        }
        
        /* Bio 部分特殊样式 */
        .bio-text {
            text-align: justify;
            line-height: 1.8;
            font-size: 1rem;
        }
        
        /* 列表样式 */
        ul {
            text-align: left;
            max-width: 700px;
            margin: 0 auto;
        }
        
        li {
            margin-bottom: 1.5rem;
            line-height: 1.6;
        }
        
        li b {
            color: #0b0b0a;
        }
        
        /* 链接样式 */
        a {
            color: #1658d3;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        /* 页脚样式 */
        footer {
            background-color: #e1e1d1;
            color: rgb(5, 4, 4);
            text-align: center;
            padding: 2rem 0;
            margin-top: 2rem;
        }
        
        .footer-content {
            max-width: 800px;
            margin: 0 auto;
            padding: 0 20px;
        }
        
        .footer-links {
            margin-bottom: 1rem;
        }
        
        .footer-links a {
            color: #0b0b0b;
            margin: 0 15px;
            font-size: 0.9rem;
        }
        
        .footer-links a:hover {
            color: #070707;
        }

        /* LinkedIn 图标样式 */
        .linkedin-icon {
            width: 24px;
            height: 24px;
            fill: #0077b5;
            transition: fill 0.3s ease;
        }
        
        .linkedin-icon:hover {
            fill: #005885;
        }
        
        /* Fun 图标样式 */
        .fun-icon {
            width: 24px;
            height: 24px;
            border-radius: 4px;
            object-fit: cover;
            transition: all 0.3s ease;
        }
        
        .fun-icon:hover {
            transform: scale(1.1);
            box-shadow: 0 2px 8px rgba(0,0,0,0.2);
        }
        
        
        /* 响应式设计 */
        @media (max-width: 768px) {
            .container {
                margin: 1rem;
                padding: 0 10px;
            }
            
            .content {
                padding: 1rem;
            }
            
            header h1 {
                font-size: 1.5rem;
            }
        }
    </style>
</head>
<body>
    <!-- 页眉 -->
    <header>
        <h1>Yueying TIAN</h1>
        <div class="header-subtitle">"I’ve only done a little, but every step matters. Thank you for being here."</div>
    </header>

    <!-- 主要内容 -->
    <div class="container">
        <div class="content">
            <!-- 个人信息区域 -->
            <div class="profile-section">
                <img src="IMG_2569.JPG" alt="Yueying Tian" class="profile-img" width="130">
                <div class="contact-info">
                    <p><strong>Work Email:</strong> yt322@sussex.ac.uk</p>
                    <p><strong>Personal Email:</strong> tianyueying163@gmail.com</p>
                </div>
            </div>
            
            <h1>Bio</h1>
            <p class="bio-text">
                 I am a Ph.D. student in Industrial Informatics and Signal Processing Research Group at the School of Engineering and Informatics in University of Sussex, advised by Prof. Chatwin and Dr. Birch. Previously, I received my MSc Computing (Distinction) at Cardiff University. I was born in 1997 in Nanjing, China.
            </p>
            
            
            <h1>Research</h1>
            <ul>   

                <li>
                    Multi-human motion tracking with transformer network augmentation.<br>
                    Philip Birch, Xudong Han, Nobuyuki Oishi, Elif Ucurum, <b>Yueying Tian</b>, Rupert Young, Chris Chatwin.<br>
                    <em>SPIE Sensors + Imaging</em>, 2025.<br>
                    <p style="margin-top:3px">
                    [<a href="https://spie.org/spie-sensors-imaging/presentation/Multi-human-motion-tracking-with-transformer-network-augmentation/13679-5">Paper</a>]
                    </p>
                </li>
                
                <li>
                    GRASPTrack: Geometry-Reasoned Association via Segmentation and Projection for Multi-Object Tracking.<br>
                    Xudong Han, Pengcheng Fang, <b>Yueying Tian</b>, Jianhui Yu, Xiaohao Cai, Daniel Roggen, Philip Birch<br>
                    <em>arXiv</em>, 2025.<br>
                    <p style="margin-top:3px">
                    [<a href="https://arxiv.org/abs/2508.08117">arXiv</a>]
                </li>
                
                <li>
                    Evaluating a Motion-Based Region Proposal Approach with Background Subtraction Methods for Small Drone Detection.<br>
                    Elif Ucurum, Phil Birch, Xudong Han, <b>Yueying Tian</b>, Rupert Young, Chris Chatwin.<br>
                    <em>Drones and Autonomous Vehicles</em>, 2025.<br>
                    <p style="margin-top:3px">
                    [<a href="https://www.sciepublish.com/article/pii/491">Paper</a>]
                    </p>
                </li>
                
                <li>
                    Enhancing Fetal Plane Classification Accuracy with Data Augmentation Using Diffusion Models.<br>
                    <b>Yueying Tian</b>, Elif Ucurum, Xudong Han, Rupert Young, Chris Chatwin, Philip Birch.<br>
                    <em>IET Image Processing</em>, 2025.<br>
                    <p style="margin-top:3px">
                    [<a href="https://ietresearch.onlinelibrary.wiley.com/doi/full/10.1049/ipr2.70151">Paper</a>][<a href="https://drive.google.com/file/d/12UpSLrRyGY4kdUscX7teyPTPELTjtkCF/view?usp=sharing">Download Synthetic Dataset</a>]
                    </p>
                </li>
                
                <li>
                    ETTrack: enhanced temporal motion predictor for multi-object tracking.<br>
                    Xudong Han, Nobuyuki Oishi, <b>Yueying Tian</b>, Elif Ucurum, Rupert Young, Chris Chatwin, Philip Birch.<br>
                    <em>Applied Intelligence</em>, 2024.<br>
                    <p style="margin-top:3px">
                    [<a href="https://link.springer.com/article/10.1007/s10489-024-05866-4">Paper</a>][<a href="https://arxiv.org/abs/2405.15755">arXiv</a>]
                    </p>
                </li>
                
                <li>
                    Improving pulmonary CT image generation with transformer-based generative adversarial networks.<br>
                    <b>Yueying Tian</b>, Xudong Han, Elif Ucurum, Chris Chatwin, Philip Birch, Rupert Young.<br>
                    <em>Pattern Recognition and Prediction XXXV; Proceedings of SPIE - The International Society for Optical Engineering</em>, 2024.<br>
                    <p style="margin-top:3px">
                    [<a href="https://www.spiedigitallibrary.org/conference-proceedings-of-spie/13040/1304002/Improving-pulmonary-CT-image-generation-with-transformer-based-generative-adversarial/10.1117/12.3017971.full">Paper</a>]
                    </p>
                </li>
            </ul>
         
            <h1>Teaching</h1>    
            <p><strong>University of Sussex</strong></p>
            <p>Doctoral Tutor, 521H3: Image Processing (2024)</p>
            <p>Doctoral Tutor, H7129: Applied Technology (2023)</p>
            <p>Doctoral Tutor, H7125: Applied Technology for Product Design (2023)</p>
        </div>
    </div>

  <!-- 页脚 -->
    <footer>
        <div class="footer-content">
            <div class="footer-links">
                <a href="https://www.linkedin.com/in/yueying-tian-59009615a/" target="_blank" title="LinkedIn">
                    <svg class="linkedin-icon" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
                        <path d="M20.447 20.452h-3.554v-5.569c0-1.328-.027-3.037-1.852-3.037-1.853 0-2.136 1.445-2.136 2.939v5.667H9.351V9h3.414v1.561h.046c.477-.9 1.637-1.85 3.37-1.85 3.601 0 4.267 2.37 4.267 5.455v6.286zM5.337 7.433c-1.144 0-2.063-.926-2.063-2.065 0-1.138.92-2.063 2.063-2.063 1.14 0 2.064.925 2.064 2.063 0 1.139-.925 2.065-2.064 2.065zm1.782 13.019H3.555V9h3.564v11.452zM22.225 0H1.771C.792 0 0 .774 0 1.729v20.542C0 23.227.792 24 1.771 24h20.451C23.2 24 24 23.227 24 22.271V1.729C24 .774 23.2 0 22.222 0h.003z"/>
                    </svg>
                </a>
                <a href="fun.html" title="Fun">
                    <img src="IMG_2561.jpg" alt="Fun" class="fun-icon">
                </a>
            </div>
            <p>&copy; 2025 Yueying Tian . </p>
        </div>
    </footer>
</body>
</html>
